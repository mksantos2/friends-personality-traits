{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_friends.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6jfOmNoChP",
        "colab_type": "text"
      },
      "source": [
        "#Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IfaXWNwopbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k1Gknc73XpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q convokit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDt1tAp3Yom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "34aa985d-f45f-4980-9dac-cbb80dbd5a01"
      },
      "source": [
        "from convokit import Corpus, download\n",
        "corpus = Corpus(filename=download(\"friends-corpus\"))\n",
        "\n",
        "corpus.print_summary_stats()\n",
        "data2 = corpus.get_utterances_dataframe()\n",
        "\n",
        "\n",
        "data1 = data2[['text', 'speaker']]\n",
        "data1 = data1.reset_index()\n",
        "data1 = data1.drop('id',axis=1)\n",
        "\n",
        "\n",
        "np.savetxt(r'test.txt', data1.values, fmt='%s')\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset already exists at /root/.convokit/downloads/friends-corpus\n",
            "Number of Speakers: 700\n",
            "Number of Utterances: 67373\n",
            "Number of Conversations: 3107\n",
            "                                                    text          speaker\n",
            "0      There's nothing to tell! He's just some guy I ...    Monica Geller\n",
            "1      C'mon, you're going out with the guy! There's ...   Joey Tribbiani\n",
            "2      All right Joey, be nice. So does he have a hum...    Chandler Bing\n",
            "3                               Wait, does he eat chalk?    Phoebe Buffay\n",
            "4                                                         TRANSCRIPT_NOTE\n",
            "...                                                  ...              ...\n",
            "67368                            Oh, it's gonna be okay.    Chandler Bing\n",
            "67369  Do you guys have to go to the new house right ...     Rachel Green\n",
            "67370                                  We got some time.    Monica Geller\n",
            "67371                   Okay, should we get some coffee?     Rachel Green\n",
            "67372                                       Sure. Where?    Chandler Bing\n",
            "\n",
            "[67373 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5z7xK5a3h1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7ad9fd6f-247c-49dd-b3f2-e4f36d7a9c32"
      },
      "source": [
        "for i in range(len(data1)):\n",
        "    if(data1.iloc[i][-1] == 'Chandler Bing'):\n",
        "        data1.loc[i][-1] = 'c'\n",
        "    elif(data1.iloc[i][-1] == 'Rachel Green'):\n",
        "        data1.loc[i][-1] = 'r'\n",
        "    elif(data1.iloc[i][-1] == 'Ross Geller'):\n",
        "        data1.loc[i][-1] = 'R'\n",
        "    elif(data1.iloc[i][-1] == 'Monica Geller'):\n",
        "        data1.loc[i][-1] = 'm'\n",
        "    elif(data1.iloc[i][-1] == 'Phoebe Buffay'):\n",
        "        data1.loc[i][-1] = 'p'\n",
        "    elif(data1.iloc[i][-1] == 'Joey Tribbiani'):\n",
        "        data1.loc[i][-1] = 'j'\n",
        "    else:\n",
        "        data1.loc[i][-1] = 'o'\n",
        "\n",
        "data1.sample(frac=1) \n",
        "data1.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
              "      <td>j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait, does he eat chalk?</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>o</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text speaker\n",
              "0  There's nothing to tell! He's just some guy I ...       m\n",
              "1  C'mon, you're going out with the guy! There's ...       j\n",
              "2  All right Joey, be nice. So does he have a hum...       c\n",
              "3                           Wait, does he eat chalk?       p\n",
              "4                                                          o"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0RUqwWJ50JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "f945ba0c-c97e-4a71-8151-b6edaac56c5b"
      },
      "source": [
        "\n",
        "data1 = data1[data1['speaker'] != 'o']\n",
        "print(data1.count())\n",
        "print(data1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text       51312\n",
            "speaker    51312\n",
            "dtype: int64\n",
            "                                                    text speaker\n",
            "0      There's nothing to tell! He's just some guy I ...       m\n",
            "1      C'mon, you're going out with the guy! There's ...       j\n",
            "2      All right Joey, be nice. So does he have a hum...       c\n",
            "3                               Wait, does he eat chalk?       p\n",
            "5      Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                  ...     ...\n",
            "67368                            Oh, it's gonna be okay.       c\n",
            "67369  Do you guys have to go to the new house right ...       r\n",
            "67370                                  We got some time.       m\n",
            "67371                   Okay, should we get some coffee?       r\n",
            "67372                                       Sure. Where?       c\n",
            "\n",
            "[51312 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVzDbh9FW2wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8919f780-5bab-4b9b-c48b-8a745117210a"
      },
      "source": [
        "data1 = data1.reset_index(drop=True)\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text speaker\n",
            "0      There's nothing to tell! He's just some guy I ...       m\n",
            "1      C'mon, you're going out with the guy! There's ...       j\n",
            "2      All right Joey, be nice. So does he have a hum...       c\n",
            "3                               Wait, does he eat chalk?       p\n",
            "4      Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                  ...     ...\n",
            "51307                            Oh, it's gonna be okay.       c\n",
            "51308  Do you guys have to go to the new house right ...       r\n",
            "51309                                  We got some time.       m\n",
            "51310                   Okay, should we get some coffee?       r\n",
            "51311                                       Sure. Where?       c\n",
            "\n",
            "[51312 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBFFQjcC3tU",
        "colab_type": "text"
      },
      "source": [
        "#LSTM - nivel de caracter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr9J6UTjC9lU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math\n",
        "\n",
        "import torch.utils.data as utils\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torchvision\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.utils.data as utils\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ko78sxP4VI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "6b2d1011-73a8-466b-b9ff-1c33f1c2e97a"
      },
      "source": [
        "datat = data1[50001:]\n",
        "print(datat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text speaker\n",
            "50001          Yeah, you miss alot, when you're moo-ing.       m\n",
            "50002  Oh! It was our pleasure. We are so much enjoyi...       m\n",
            "50003  Oh, uhm, okay, uhm, do you mind if we ask you ...       c\n",
            "50004                                      That's great.       c\n",
            "50005                                    How's that now?       m\n",
            "...                                                  ...     ...\n",
            "51307                            Oh, it's gonna be okay.       c\n",
            "51308  Do you guys have to go to the new house right ...       r\n",
            "51309                                  We got some time.       m\n",
            "51310                   Okay, should we get some coffee?       r\n",
            "51311                                       Sure. Where?       c\n",
            "\n",
            "[1311 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK9FK6aoRAKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "3bbb4304-15c7-4bd5-f8b0-eba4ea788120"
      },
      "source": [
        "data1 = data1[:5000]\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text speaker\n",
            "0     There's nothing to tell! He's just some guy I ...       m\n",
            "1     C'mon, you're going out with the guy! There's ...       j\n",
            "2     All right Joey, be nice. So does he have a hum...       c\n",
            "3                              Wait, does he eat chalk?       p\n",
            "4     Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                 ...     ...\n",
            "4995                  You gotta tell Ross how you feel.       j\n",
            "4996  Come on. How can I just tell him? What about J...       r\n",
            "4997  What about her? They've only been going out fo...       j\n",
            "4998                        I don't know, I don't know.       r\n",
            "4999  Look, Rach, Rach! I've been with my share of w...       j\n",
            "\n",
            "[5000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy51TVHoEZOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7c828ae3-cd4b-4e62-e9b3-7a5d91ec2e8b"
      },
      "source": [
        "chunk_len = 150\n",
        "\n",
        "# Gera um pedaço aleatório de texto com o tamanho especificado em chuck_len\n",
        "def random_chunk():\n",
        "    index = random.randint(0, len(data1)-1)\n",
        "    \n",
        "    data = data1.iloc[index][0]\n",
        "    \n",
        "    for i in range(200-len(data)):#normaliza os chunks com tamanho igual\n",
        "        data+='/0'\n",
        "        \n",
        "    return data, index\n",
        "    \n",
        "print(random_chunk())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Does he know?/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0', 3306)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "que-V2Q8CMpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWFa64edMRcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0dc8b48b-01e3-44ac-c096-a4e2aaa3b1d2"
      },
      "source": [
        "file = open('test.txt').read()\n",
        "all_characters = ''.join(set(file))\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print(n_characters)\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6ztL4vuP,#xER[]nl${VWK?J%+o>i&QjsghUrDH(NwT'`cXY/}Id3pqGkmZ0M1F:f52)\n",
            "987;!-b_ Ca\".OyB*eSA\n",
            "89\n",
            "file_len = 4169043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlaIuNLIEH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "498bbef9-e1bc-4936-8e1b-6818846b0ea7"
      },
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        except:\n",
        "            print(c)\n",
        "            raise\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([79, 75, 45, 37, 11, 62])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujFfvD_NIIWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "3681ad9d-acde-46a9-e868-451956bddd5e"
      },
      "source": [
        "# Gera um 'exemplo' aleatório (um pedaço aleatório convertido para lista de inteiros)\n",
        "def random_training_set():    \n",
        "    chunk, index = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = data1.iloc[index][-1]\n",
        "    target = char_tensor(target)\n",
        "    return inp, target\n",
        "\n",
        "print(random_training_set())\n",
        "#tensor = random_training_set()\n",
        "#print(tensor)\n",
        "#if(tensor[0][199] == 3) :\n",
        "   # print(\"sim!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([50, 77, 79, 57, 77, 15, 26,  2, 77, 79, 77, 75, 79, 75, 83, 73, 77, 47,\n",
            "        26,  6, 77, 56, 15, 26, 41, 77, 41, 34, 79,  2, 22, 77, 50, 77, 32, 41,\n",
            "        86, 79, 36, 77,  2, 26, 77, 33, 26, 51,  8, 77, 31,  6, 32,  2, 77, 75,\n",
            "        86, 45, 79,  6, 32, 86, 77, 83, 26,  6, 77, 33, 86,  2, 77, 32, 26, 77,\n",
            "         6, 53,  2, 28, 33, 34,  2, 77, 86,  5, 86, 36, 83, 77,  2, 28, 57, 86,\n",
            "        77, 41, 86, 81, 81, 81, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59,\n",
            "        48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48, 59, 48]), tensor([36]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpngngmGILoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden, hidden2):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, (hidden, hidden2) = self.lstm(input.view(1, 1, -1), (hidden, hidden2))\n",
        "        decoded_output = self.decoder(output.view(1, -1))\n",
        "        return decoded_output, hidden, hidden2\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqP1XbPSKGQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um texto iniciando com \"prime_str\" de tamanho \"predict_len\" e variação definida por \"temperature\"\n",
        "def evaluate(prime_str='A', predict_len=1, temperature=0.8):\n",
        "    hidden = rnn.init_hidden().cuda()\n",
        "    hidden2 = rnn.init_hidden().cuda()\n",
        "    prime_input = char_tensor(prime_str).cuda()\n",
        "    predicted = ''\n",
        "\n",
        "    # prime_str é o texto inicial que o gerado irá completar\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden, hidden2 = rnn(prime_input[p], hidden, hidden2)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden, hidden2 = rnn(inp, hidden, hidden2)\n",
        "        \n",
        "        # Usa a temperatura para amostrar a distribuição e escolher a saída probabilísticamente\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Adiciona o caracter predito à string de saída\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char).cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B727cBfyKO-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treina sobre um exemplo (i.e. uma amostragem do texto)\n",
        "\n",
        "def train(inp, target):\n",
        "   \n",
        "    hidden = rnn.init_hidden()\n",
        "    hidden2 = rnn.init_hidden()\n",
        "\n",
        "    rnn.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    inp = inp.cuda()\n",
        "    hidden = hidden.cuda()\n",
        "    hidden2 = hidden2.cuda()\n",
        "    for c in range(chunk_len):\n",
        "        if(inp[c] != 79 or inp[c] != 74):\n",
        "            output, hidden, hidden2 = rnn(inp[c], hidden, hidden2)\n",
        "            loss += loss_metric(output, target[0].unsqueeze(0))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return (loss.data.item() / chunk_len), hidden, hidden2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyBV87r7RsGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cHeXrNVKSAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32c0a8e0-6de2-49c2-a6ac-307c36338a92"
      },
      "source": [
        "n_epochs = 100\n",
        "print_every = 1\n",
        "hidden_size = 512\n",
        "n_layers = 4\n",
        "lr = 0.0005\n",
        "\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "rnn.cuda()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "loss_metric = nn.CrossEntropyLoss()\n",
        "h1 = 0\n",
        "h2 = 0\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    example = random_training_set()\n",
        "    #print(example[0])\n",
        "    loss, h1, h2 = train(example[0].cuda(),example[1].cuda())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "       # print(evaluate('The', 100), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 0s (1 1%) 4.4641]\n",
            "[0m 0s (2 2%) 4.3351]\n",
            "[0m 0s (3 3%) 4.4744]\n",
            "[0m 1s (4 4%) 4.4942]\n",
            "[0m 1s (5 5%) 4.5410]\n",
            "[0m 1s (6 6%) 3.9702]\n",
            "[0m 2s (7 7%) 4.5203]\n",
            "[0m 2s (8 8%) 4.4958]\n",
            "[0m 2s (9 9%) 3.1066]\n",
            "[0m 3s (10 10%) 3.3943]\n",
            "[0m 3s (11 11%) 2.5331]\n",
            "[0m 3s (12 12%) 3.5619]\n",
            "[0m 3s (13 13%) 3.6429]\n",
            "[0m 4s (14 14%) 1.6440]\n",
            "[0m 4s (15 15%) 1.7144]\n",
            "[0m 4s (16 16%) 3.0342]\n",
            "[0m 5s (17 17%) 1.4784]\n",
            "[0m 5s (18 18%) 2.5386]\n",
            "[0m 5s (19 19%) 4.0982]\n",
            "[0m 6s (20 20%) 1.5183]\n",
            "[0m 6s (21 21%) 2.0957]\n",
            "[0m 6s (22 22%) 1.8874]\n",
            "[0m 7s (23 23%) 2.1648]\n",
            "[0m 7s (24 24%) 2.0340]\n",
            "[0m 7s (25 25%) 3.5304]\n",
            "[0m 7s (26 26%) 1.8438]\n",
            "[0m 8s (27 27%) 2.0491]\n",
            "[0m 8s (28 28%) 1.1495]\n",
            "[0m 8s (29 28%) 1.1142]\n",
            "[0m 9s (30 30%) 2.9759]\n",
            "[0m 9s (31 31%) 0.9795]\n",
            "[0m 9s (32 32%) 2.1708]\n",
            "[0m 10s (33 33%) 2.2847]\n",
            "[0m 10s (34 34%) 1.7779]\n",
            "[0m 10s (35 35%) 2.0212]\n",
            "[0m 10s (36 36%) 0.9381]\n",
            "[0m 11s (37 37%) 2.2986]\n",
            "[0m 11s (38 38%) 1.7884]\n",
            "[0m 11s (39 39%) 3.8757]\n",
            "[0m 12s (40 40%) 1.6682]\n",
            "[0m 12s (41 41%) 3.6517]\n",
            "[0m 12s (42 42%) 1.6882]\n",
            "[0m 13s (43 43%) 1.5072]\n",
            "[0m 13s (44 44%) 1.3892]\n",
            "[0m 13s (45 45%) 1.3182]\n",
            "[0m 13s (46 46%) 1.8640]\n",
            "[0m 14s (47 47%) 1.8075]\n",
            "[0m 14s (48 48%) 1.0985]\n",
            "[0m 14s (49 49%) 1.8214]\n",
            "[0m 15s (50 50%) 1.9223]\n",
            "[0m 15s (51 51%) 2.8006]\n",
            "[0m 15s (52 52%) 1.6634]\n",
            "[0m 16s (53 53%) 2.9856]\n",
            "[0m 16s (54 54%) 2.1773]\n",
            "[0m 16s (55 55%) 2.1728]\n",
            "[0m 17s (56 56%) 1.4121]\n",
            "[0m 17s (57 56%) 1.9287]\n",
            "[0m 17s (58 57%) 2.8103]\n",
            "[0m 17s (59 59%) 1.8381]\n",
            "[0m 18s (60 60%) 2.2870]\n",
            "[0m 18s (61 61%) 2.5703]\n",
            "[0m 18s (62 62%) 2.4454]\n",
            "[0m 19s (63 63%) 1.9153]\n",
            "[0m 19s (64 64%) 1.9604]\n",
            "[0m 19s (65 65%) 1.9362]\n",
            "[0m 20s (66 66%) 1.8775]\n",
            "[0m 20s (67 67%) 1.8288]\n",
            "[0m 20s (68 68%) 2.0472]\n",
            "[0m 20s (69 69%) 1.8152]\n",
            "[0m 21s (70 70%) 1.8285]\n",
            "[0m 21s (71 71%) 1.5334]\n",
            "[0m 21s (72 72%) 1.9546]\n",
            "[0m 22s (73 73%) 2.0615]\n",
            "[0m 22s (74 74%) 1.8466]\n",
            "[0m 22s (75 75%) 1.6733]\n",
            "[0m 23s (76 76%) 1.3481]\n",
            "[0m 23s (77 77%) 1.6305]\n",
            "[0m 23s (78 78%) 2.2230]\n",
            "[0m 23s (79 79%) 1.3006]\n",
            "[0m 24s (80 80%) 1.4297]\n",
            "[0m 24s (81 81%) 2.2217]\n",
            "[0m 24s (82 82%) 1.8401]\n",
            "[0m 25s (83 83%) 2.1350]\n",
            "[0m 25s (84 84%) 1.8264]\n",
            "[0m 25s (85 85%) 1.9603]\n",
            "[0m 26s (86 86%) 1.8360]\n",
            "[0m 26s (87 87%) 1.7159]\n",
            "[0m 26s (88 88%) 1.5410]\n",
            "[0m 26s (89 89%) 1.5566]\n",
            "[0m 27s (90 90%) 1.3843]\n",
            "[0m 27s (91 91%) 3.4793]\n",
            "[0m 27s (92 92%) 1.2050]\n",
            "[0m 28s (93 93%) 2.9417]\n",
            "[0m 28s (94 94%) 3.4001]\n",
            "[0m 28s (95 95%) 1.6700]\n",
            "[0m 29s (96 96%) 3.2261]\n",
            "[0m 29s (97 97%) 2.1720]\n",
            "[0m 29s (98 98%) 0.9407]\n",
            "[0m 29s (99 99%) 1.7916]\n",
            "[0m 30s (100 100%) 0.9249]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDpZwbwzLFAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14bd7ba4-3169-42d4-b3f5-9cb635e9dbac"
      },
      "source": [
        "#usando o evaluate para avaliar o modelo com o dataset de test\n",
        "datat = datat[datat['text'].map(len) > 15]\n",
        "\n",
        "correct = 0\n",
        "loss = 0\n",
        "\n",
        "for i in range(len(datat)):\n",
        "    predict = evaluate(datat.iloc[i][0])\n",
        "    label = datat.iloc[i][-1]\n",
        "    if(predict == label):\n",
        "        correct+=1\n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "accuracy = correct/(len(datat))\n",
        "\n",
        "\n",
        "\n",
        "print('Acurácia: %d%%'  % (accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiQqwunKy00",
        "colab_type": "text"
      },
      "source": [
        "##Teste LSTM caracter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTBais5aK6iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# carregar o dataset de test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poDyXIMzO43t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b1dc917b-e1b6-48e9-9952-4345d25e8224"
      },
      "source": [
        "print(h1, h2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.0984,  0.4468,  0.9055,  ..., -0.0425,  0.9711,  0.1457]],\n",
            "\n",
            "        [[-0.6505, -0.4054, -0.9629,  ...,  0.9957,  0.9785,  0.9475]],\n",
            "\n",
            "        [[ 0.9774,  0.0373, -0.0968,  ...,  0.9955, -0.9904, -0.9782]],\n",
            "\n",
            "        [[ 0.3751,  0.0068, -0.8749,  ..., -0.6759,  0.8896, -0.6378]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>) tensor([[[ -0.6777,   5.2808,  17.9910,  ...,  -0.2083,   5.5516,   0.3916]],\n",
            "\n",
            "        [[ -2.1585,  -3.5053,  -5.5215,  ...,  44.2852,  18.6001,  11.6609]],\n",
            "\n",
            "        [[ 24.8295,   1.1272,  -1.1426,  ...,  52.9754, -22.6928, -16.7860]],\n",
            "\n",
            "        [[  3.4405,   0.0531,  -3.7376,  ...,  -2.8014,  10.2565,  -7.9510]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utEKI9_50CUW",
        "colab_type": "text"
      },
      "source": [
        "#DATASET 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nM_8Ct9lW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = pd.read_csv(\"friends-personality.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsnkh0eUENwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1c6f544c-6821-4fb1-f938-b1703c6fb66b"
      },
      "source": [
        "print(data2.iloc[4,3])\n",
        "data2.iloc[4,3] = 'c'\n",
        "print(data2.iloc[4,3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Monica Geller\n",
            "c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc26ri4g0pSX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "78159043-3d7f-4e20-83d6-cc6cb7cbdea6"
      },
      "source": [
        "for i in range(len(data2)):\n",
        "    if(data2.iloc[i][4] == 1):\n",
        "        data2.iloc[i,3] = 'a'\n",
        "    elif(data2.iloc[i][5] == 1):\n",
        "        data2.iloc[i,3] = 'c'\n",
        "    elif(data2.iloc[i][6] == 1):\n",
        "        data2.iloc[i,3] = 'e'\n",
        "    elif(data2.iloc[i][7] == 1):\n",
        "        data2.iloc[i,3] = 'o'\n",
        "    elif(data2.iloc[i][8] == 1):\n",
        "        data2.iloc[i,3] = 'n'\n",
        "\n",
        "data2.sample(frac=1) \n",
        "data2.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>scene_id</th>\n",
              "      <th>text</th>\n",
              "      <th>character</th>\n",
              "      <th>cAGR</th>\n",
              "      <th>cCON</th>\n",
              "      <th>cEXT</th>\n",
              "      <th>cOPN</th>\n",
              "      <th>cNEU</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>01_e01_c01</td>\n",
              "      <td>&lt;b&gt;s01_e01_c01(1) for Joey Tribbiani&lt;/b&gt;&lt;br&gt;&lt;b...</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>01_e01_c02</td>\n",
              "      <td>&lt;b&gt;s01_e01_c02(0) for Chandler Bing&lt;/b&gt;&lt;br&gt;&lt;br...</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>01_e01_c04</td>\n",
              "      <td>&lt;b&gt;s01_e01_c04(0) for Chandler Bing&lt;/b&gt;&lt;br&gt;&lt;br...</td>\n",
              "      <td>n</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>01_e01_c05</td>\n",
              "      <td>&lt;b&gt;s01_e01_c05(0) for Paul&lt;/b&gt;&lt;br&gt;&lt;br&gt;&lt;b&gt;Monic...</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>01_e01_c08</td>\n",
              "      <td>&lt;b&gt;s01_e01_c08(0) for Monica Geller&lt;/b&gt;&lt;br&gt;&lt;br...</td>\n",
              "      <td>a</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    scene_id  ... cOPN cNEU\n",
              "0           0  01_e01_c01  ...    0    1\n",
              "1           1  01_e01_c02  ...    1    1\n",
              "2           2  01_e01_c04  ...    0    1\n",
              "3           3  01_e01_c05  ...    1    0\n",
              "4           4  01_e01_c08  ...    1    1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du7PaxcUS8qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "d7e3239b-aa66-401b-b1c0-f643db2e834c"
      },
      "source": [
        "datat2 = data2[571:]\n",
        "print(datat2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0    scene_id  ... cOPN cNEU\n",
            "571         571  04_e10_c03  ...    1    1\n",
            "572         572  04_e10_c08  ...    1    1\n",
            "573         573  04_e10_c13  ...    1    1\n",
            "574         574  04_e10_c13  ...    1    1\n",
            "575         575  04_e10_c14  ...    0    0\n",
            "..          ...         ...  ...  ...  ...\n",
            "706         706  04_e24_c18  ...    0    0\n",
            "707         707  04_e24_c19  ...    1    0\n",
            "708         708  04_e24_c19  ...    1    0\n",
            "709         709  04_e24_c20  ...    0    1\n",
            "710         710  04_e24_c24  ...    1    1\n",
            "\n",
            "[140 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyTqR9Y5TLLD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "ee308e97-576e-4c05-d617-5677c779c2f3"
      },
      "source": [
        "datat2 = data2[:570]\n",
        "print(datat2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Unnamed: 0    scene_id  ... cOPN cNEU\n",
            "0             0  01_e01_c01  ...    0    1\n",
            "1             1  01_e01_c02  ...    1    1\n",
            "2             2  01_e01_c04  ...    0    1\n",
            "3             3  01_e01_c05  ...    1    0\n",
            "4             4  01_e01_c08  ...    1    1\n",
            "..          ...         ...  ...  ...  ...\n",
            "565         565  04_e09_c05  ...    1    0\n",
            "566         566  04_e09_c09  ...    0    1\n",
            "567         567  04_e09_c13  ...    1    0\n",
            "568         568  04_e10_c02  ...    1    0\n",
            "569         569  04_e10_c02  ...    0    0\n",
            "\n",
            "[570 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B53lwsEkG0f4",
        "colab_type": "text"
      },
      "source": [
        "#LSTM 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8rAum2zEaFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train2(inp, target, h1, h2, pretrain=0):\n",
        "    if pretrain == 0:\n",
        "        hidden = rnn.init_hidden()\n",
        "        hidden2 = rnn.init_hidden()\n",
        "    else:\n",
        "        hidden = h1\n",
        "        hidden = h2\n",
        "        \n",
        "    rnn.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    inp = inp.cuda()\n",
        "    hidden = hidden.cuda()\n",
        "    hidden2 = hidden2.cuda()\n",
        "    for c in range(chunk_len):\n",
        "        if(inp[c] != 79 or inp[c] != 74):\n",
        "            output, hidden, hidden2 = rnn(inp[c], hidden, hidden2)\n",
        "            loss += loss_metric(output, target[0].unsqueeze(0))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.data.item() / chunk_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbDzs9KYR4kN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35d88f0f-c76b-4eee-87a0-34bbb25bfcd7"
      },
      "source": [
        "print(data2.iloc[23][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<b>s01_e04_c02(0) for Monica Geller</b><br><br><b>Monica Geller</b>: How does she do that?<br><br><b>Ross Geller</b>: I cannot sleep in a public place.<br><br><b>Monica Geller</b>: Would you look at her? She is so peaceful.<br><br><b>Phoebe Buffay</b>: (waking and startling them) Oh! What what what! ...Hi.<br><br><b>Ross Geller</b>: It's okay, y'know, you just nodded off again.<br><br><b>Monica Geller</b>: What's going on with you?<br><br><b>Phoebe Buffay</b>: I got no sleep last night!<br><br><b>Ross Geller</b>: Why?<br><br><b>Phoebe Buffay</b>: My grandmother has this new boyfriend, and they're both kind of insecure in bed. Oh, and deaf. So they're constantly, like, having to reassure each other that they're having a good time. You have no idea how loud they are!<br><br><b>Monica Geller</b>: Well, if you want, you can stay with Rachel and me tonight.<br><br>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTQF3j9KRg0D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2268f61d-85eb-4cdf-b130-e202e89f8b4e"
      },
      "source": [
        "chunk_len = 150\n",
        "\n",
        "# Gera um pedaço aleatório de texto com o tamanho especificado em chuck_len\n",
        "def random_chunk2():\n",
        "    index = random.randint(0, len(data2)-1)\n",
        "    \n",
        "    data = data2.iloc[index][2]\n",
        "    \n",
        "    for i in range(200-len(data)):#normaliza os chunks com tamanho igual\n",
        "        data+='/0'\n",
        "        \n",
        "    return data, index\n",
        "    \n",
        "print(random_chunk2())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"<b>s04_e24_c13(0) for Phoebe</b><br><br><b>Joey</b>: Hello?<br><br><b>Phoebe</b>: (Angrily.) Hey, were the hell have you been?!<br><br><b>Joey</b>: Hey. I spent the night out. I met this cute bridesmaid. She is so...<br><br><b>Phoebe</b>: I don't want to hear about her!!<br><br><b>Joey</b>: Ahh Pheebs, you know you're still my number one girl.<br><br><b>Phoebe</b>: No! No, we have an emergency. Okay? Rachel's coming to London.<br><br><b>Joey</b>: Ohh great!!!<br><br><b>Phoebe</b>: No it's not great. No, she's coming to tell Ross that she loves him.<br><br><b>Joey</b>: (Confused.) But, he loves Emily?<br><br><b>Phoebe</b>: I KNOW THAT!!! You have to stop her!! She's going to ruin the wedding!!<br><br><b>Joey</b>: Okay.<br><br>\", 700)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9b2B9zPeLdU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "20b699f3-91ea-456a-e99b-c02fbdd876b9"
      },
      "source": [
        "chunk, index = random_chunk2()\n",
        "print(chunk)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<b>s02_e24_c04(0) for Richard</b><br><br><b>Monica Geller</b>: (holding up a blanket) Where's Benny? (drops the blanket) There he is! (does it again) Where's Benny, there he is.<br><br><b>Richard</b>: Awww! You know that's probably why babies learn to talk, so they can tell grown ups to cut it out.<br><br><b>Monica Geller</b>: Hey, you know I got a question for ya. Just a little thing, no pressure.<br><br><b>Richard</b>: Okay.<br><br><b>Monica Geller</b>: Did you ever, uh, like, think about the future?<br><br><b>Richard</b>: Sure I do.<br><br><b>Monica Geller</b>: Yeah, am I in it?<br><br><b>Richard</b>: Honey, you are in it.<br><br><b>Monica Geller</b>: Oh God, you are about to get sooo lucky.<br><br><b>Richard</b>: Oh, yeah!<br><br><b>Monica Geller</b>: Keep talkin'.<br><br><b>Richard</b>: Well, uh, sometimes I think about selling my practice, we could move to France, make French toast.<br><br><b>Monica Geller</b>: Okay, so, uh, we're in France, we're making the toast. Do you see a little bassinet in the corner?<br><br><b>Richard</b>: Like a hound?<br><br><b>Monica Geller</b>: Not a basset, a bassinet.<br><br><b>Richard</b>: You really need the bassinet?<br><br>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52rOQCFqQ51F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d214ccb7-2e70-4d42-db5d-43562753d142"
      },
      "source": [
        "def random_training_set2():    \n",
        "    chunk, index = random_chunk2()\n",
        "    inp = char_tensor2(chunk)\n",
        "    target = data2.iloc[index][3]\n",
        "    target = char_tensor2(target)\n",
        "    return inp, target\n",
        "\n",
        "print(random_training_set2())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([63, 73, 25,  ..., 73, 34, 25]), tensor([83]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9HPDgqOQOWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09a9840e-b84a-4295-df02-b160db337244"
      },
      "source": [
        "n_epochs = 100\n",
        "print_every = 1\n",
        "hidden_size = 512\n",
        "n_layers = 4\n",
        "lr = 0.0005\n",
        "\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "rnn.cuda()\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "loss_metric = nn.CrossEntropyLoss()\n",
        "h1 = 0\n",
        "h2 = 0\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    example = random_training_set2()\n",
        "    #print(example[0])\n",
        "    if i == 1:\n",
        "        loss = train2(example[0].cuda(),example[1].cuda(), h1, h2, 1)\n",
        "    else:\n",
        "        loss = train2(example[0].cuda(),example[1].cuda(), h1, h2, 0)       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "       # print(evaluate('The', 100), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 0s (1 1%) 4.4607]\n",
            "[0m 0s (2 2%) 4.4661]\n",
            "[0m 0s (3 3%) 4.4909]\n",
            "[0m 1s (4 4%) 4.3434]\n",
            "[0m 1s (5 5%) 4.2101]\n",
            "[0m 1s (6 6%) 4.2032]\n",
            "[0m 2s (7 7%) 3.5066]\n",
            "[0m 2s (8 8%) 3.0426]\n",
            "[0m 2s (9 9%) 2.3719]\n",
            "[0m 3s (10 10%) 1.6188]\n",
            "[0m 3s (11 11%) 0.8923]\n",
            "[0m 3s (12 12%) 3.1209]\n",
            "[0m 3s (13 13%) 0.3072]\n",
            "[0m 4s (14 14%) 0.2353]\n",
            "[0m 4s (15 15%) 2.9412]\n",
            "[0m 4s (16 16%) 0.1935]\n",
            "[0m 5s (17 17%) 0.2044]\n",
            "[0m 5s (18 18%) 0.2115]\n",
            "[0m 5s (19 19%) 8.5337]\n",
            "[0m 6s (20 20%) 0.2338]\n",
            "[0m 6s (21 21%) 4.4551]\n",
            "[0m 6s (22 22%) 7.8094]\n",
            "[0m 6s (23 23%) 0.3237]\n",
            "[0m 7s (24 24%) 7.0873]\n",
            "[0m 7s (25 25%) 0.3916]\n",
            "[0m 7s (26 26%) 1.3865]\n",
            "[0m 8s (27 27%) 3.3068]\n",
            "[0m 8s (28 28%) 0.5516]\n",
            "[0m 8s (29 28%) 2.8486]\n",
            "[0m 9s (30 30%) 0.6532]\n",
            "[0m 9s (31 31%) 7.0841]\n",
            "[0m 9s (32 32%) 2.1145]\n",
            "[0m 10s (33 33%) 1.2221]\n",
            "[0m 10s (34 34%) 1.2092]\n",
            "[0m 10s (35 35%) 1.5068]\n",
            "[0m 10s (36 36%) 1.1396]\n",
            "[0m 11s (37 37%) 1.2274]\n",
            "[0m 11s (38 38%) 5.9018]\n",
            "[0m 11s (39 39%) 1.2861]\n",
            "[0m 12s (40 40%) 1.2648]\n",
            "[0m 12s (41 41%) 1.3960]\n",
            "[0m 12s (42 42%) 1.1690]\n",
            "[0m 13s (43 43%) 1.4254]\n",
            "[0m 13s (44 44%) 1.1689]\n",
            "[0m 13s (45 45%) 1.3780]\n",
            "[0m 13s (46 46%) 1.0589]\n",
            "[0m 14s (47 47%) 1.0363]\n",
            "[0m 14s (48 48%) 3.6050]\n",
            "[0m 14s (49 49%) 1.4063]\n",
            "[0m 15s (50 50%) 4.6015]\n",
            "[0m 15s (51 51%) 3.2681]\n",
            "[0m 15s (52 52%) 0.9157]\n",
            "[0m 16s (53 53%) 1.4875]\n",
            "[0m 16s (54 54%) 1.4751]\n",
            "[0m 16s (55 55%) 0.9058]\n",
            "[0m 16s (56 56%) 1.4958]\n",
            "[0m 17s (57 56%) 0.9119]\n",
            "[0m 17s (58 57%) 0.8997]\n",
            "[0m 17s (59 59%) 0.8673]\n",
            "[0m 18s (60 60%) 1.7385]\n",
            "[0m 18s (61 61%) 0.7939]\n",
            "[0m 18s (62 62%) 1.5688]\n",
            "[0m 19s (63 63%) 0.7346]\n",
            "[0m 19s (64 64%) 0.7010]\n",
            "[0m 19s (65 65%) 0.6562]\n",
            "[0m 20s (66 66%) 2.0015]\n",
            "[0m 20s (67 67%) 2.0037]\n",
            "[0m 20s (68 68%) 0.5689]\n",
            "[0m 20s (69 69%) 0.5519]\n",
            "[0m 21s (70 70%) 0.5264]\n",
            "[0m 21s (71 71%) 1.8927]\n",
            "[0m 21s (72 72%) 1.8355]\n",
            "[0m 22s (73 73%) 0.4970]\n",
            "[0m 22s (74 74%) 0.4998]\n",
            "[0m 22s (75 75%) 0.4936]\n",
            "[0m 23s (76 76%) 0.4789]\n",
            "[0m 23s (77 77%) 2.3919]\n",
            "[0m 23s (78 78%) 0.4495]\n",
            "[0m 23s (79 79%) 3.3307]\n",
            "[0m 24s (80 80%) 1.6071]\n",
            "[0m 24s (81 81%) 1.5570]\n",
            "[0m 24s (82 82%) 0.4859]\n",
            "[0m 25s (83 83%) 0.5111]\n",
            "[0m 25s (84 84%) 4.1535]\n",
            "[0m 25s (85 85%) 0.5437]\n",
            "[0m 26s (86 86%) 0.5501]\n",
            "[0m 26s (87 87%) 9.3784]\n",
            "[0m 26s (88 88%) 3.0599]\n",
            "[0m 27s (89 89%) 0.5583]\n",
            "[0m 27s (90 90%) 9.0828]\n",
            "[0m 27s (91 91%) 1.3595]\n",
            "[0m 27s (92 92%) 0.5950]\n",
            "[0m 28s (93 93%) 0.6089]\n",
            "[0m 28s (94 94%) 2.5897]\n",
            "[0m 28s (95 95%) 1.3525]\n",
            "[0m 29s (96 96%) 0.6479]\n",
            "[0m 29s (97 97%) 0.6616]\n",
            "[0m 29s (98 98%) 0.6604]\n",
            "[0m 30s (99 99%) 1.3781]\n",
            "[0m 30s (100 100%) 0.6522]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSJB93tpTalN",
        "colab_type": "text"
      },
      "source": [
        "#TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fXe1isgWMLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "1ed0f30c-9b42-4d67-db90-f30524f063ef"
      },
      "source": [
        "file = open('friends-personality.csv').read()\n",
        "all_characters2 = ''.join(set(file))\n",
        "n_characters2 = len(all_characters2)\n",
        "print(all_characters2)\n",
        "print(n_characters2)\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6ztL4vuP,#xER[]nl$VWK?J%o>i&QjsghUrDH(NwT'`cX/YId3pqGkmZ0M1F:f5<2)\n",
            "987;!-b_ Ca\".OyBeS^A\n",
            "87\n",
            "file_len = 748760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1327S7LW0Gl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fbe6e3c-99d2-49a7-bb77-7128e41cdf41"
      },
      "source": [
        "def char_tensor2(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters2.index(string[c])\n",
        "        except:\n",
        "            print(c)\n",
        "            raise\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor2('abcDEF'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([77, 73, 43, 35, 11, 59])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztAD87nKW-mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um texto iniciando com \"prime_str\" de tamanho \"predict_len\" e variação definida por \"temperature\"\n",
        "def evaluate2(prime_str='A', predict_len=1, temperature=0.8):\n",
        "    hidden = rnn.init_hidden().cuda()\n",
        "    hidden2 = rnn.init_hidden().cuda()\n",
        "    prime_input = char_tensor2(prime_str).cuda()\n",
        "    predicted = ''\n",
        "\n",
        "    # prime_str é o texto inicial que o gerado irá completar\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden, hidden2 = rnn(prime_input[p], hidden, hidden2)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden, hidden2 = rnn(inp, hidden, hidden2)\n",
        "        \n",
        "        # Usa a temperatura para amostrar a distribuição e escolher a saída probabilísticamente\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Adiciona o caracter predito à string de saída\n",
        "        predicted_char = all_characters2[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor2(predicted_char).cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R421SoZnUfM_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "13699b14-fc6e-4a9f-ceae-b00e93863138"
      },
      "source": [
        "#usando o evaluate para avaliar o modelo com o dataset de test\n",
        "datat2 = datat2[datat2['text'].map(len) > 15]\n",
        "\n",
        "correct = 0\n",
        "loss = 0\n",
        "\n",
        "for i in range(len(datat2)):\n",
        "    predict = evaluate2(datat2.iloc[i][2])\n",
        "    label = datat2.iloc[i][3]\n",
        "    #print(predict, label)\n",
        "    if(predict == label):\n",
        "        correct+=1\n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "accuracy = correct/(len(datat2))\n",
        "\n",
        "\n",
        "\n",
        "print('Acurácia: %d%%'  % (accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ-PwDtjVdhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
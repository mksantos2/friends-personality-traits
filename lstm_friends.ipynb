{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_friends.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on6jfOmNoChP",
        "colab_type": "text"
      },
      "source": [
        "#Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IfaXWNwopbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k1Gknc73XpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "794f49c3-8d08-43f5-d2bd-792cfb151ee7"
      },
      "source": [
        "!pip install -q convokit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 133kB 6.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4MB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 32.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n",
            "\u001b[?25h  Building wheel for convokit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDt1tAp3Yom",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "0bcd8ba5-be6b-453c-a795-f371ce1f7b15"
      },
      "source": [
        "from convokit import Corpus, download\n",
        "corpus = Corpus(filename=download(\"friends-corpus\"))\n",
        "\n",
        "corpus.print_summary_stats()\n",
        "data2 = corpus.get_utterances_dataframe()\n",
        "\n",
        "\n",
        "data1 = data2[['text', 'speaker']]\n",
        "data1 = data1.reset_index()\n",
        "data1 = data1.drop('id',axis=1)\n",
        "\n",
        "\n",
        "np.savetxt(r'test.txt', data1.values, fmt='%s')\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading friends-corpus to /root/.convokit/downloads/friends-corpus\n",
            "Downloading friends-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/friends-corpus/friends-corpus.zip (6.1MB)... Done\n",
            "Number of Speakers: 700\n",
            "Number of Utterances: 67373\n",
            "Number of Conversations: 3107\n",
            "                                                    text          speaker\n",
            "0      There's nothing to tell! He's just some guy I ...    Monica Geller\n",
            "1      C'mon, you're going out with the guy! There's ...   Joey Tribbiani\n",
            "2      All right Joey, be nice. So does he have a hum...    Chandler Bing\n",
            "3                               Wait, does he eat chalk?    Phoebe Buffay\n",
            "4                                                         TRANSCRIPT_NOTE\n",
            "...                                                  ...              ...\n",
            "67368                            Oh, it's gonna be okay.    Chandler Bing\n",
            "67369  Do you guys have to go to the new house right ...     Rachel Green\n",
            "67370                                  We got some time.    Monica Geller\n",
            "67371                   Okay, should we get some coffee?     Rachel Green\n",
            "67372                                       Sure. Where?    Chandler Bing\n",
            "\n",
            "[67373 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5z7xK5a3h1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8d1bfcd4-9ce4-4655-d8ee-bbc6d4185a27"
      },
      "source": [
        "for i in range(len(data1)):\n",
        "    if(data1.iloc[i][-1] == 'Chandler Bing'):\n",
        "        data1.loc[i][-1] = 'c'\n",
        "    elif(data1.iloc[i][-1] == 'Rachel Green'):\n",
        "        data1.loc[i][-1] = 'r'\n",
        "    elif(data1.iloc[i][-1] == 'Ross Geller'):\n",
        "        data1.loc[i][-1] = 'R'\n",
        "    elif(data1.iloc[i][-1] == 'Monica Geller'):\n",
        "        data1.loc[i][-1] = 'm'\n",
        "    elif(data1.iloc[i][-1] == 'Phoebe Buffay'):\n",
        "        data1.loc[i][-1] = 'p'\n",
        "    elif(data1.iloc[i][-1] == 'Joey Tribbiani'):\n",
        "        data1.loc[i][-1] = 'j'\n",
        "    else:\n",
        "        data1.loc[i][-1] = 'o'\n",
        "\n",
        "data1.sample(frac=1) \n",
        "data1.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There's nothing to tell! He's just some guy I ...</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C'mon, you're going out with the guy! There's ...</td>\n",
              "      <td>j</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All right Joey, be nice. So does he have a hum...</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Wait, does he eat chalk?</td>\n",
              "      <td>p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>o</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text speaker\n",
              "0  There's nothing to tell! He's just some guy I ...       m\n",
              "1  C'mon, you're going out with the guy! There's ...       j\n",
              "2  All right Joey, be nice. So does he have a hum...       c\n",
              "3                           Wait, does he eat chalk?       p\n",
              "4                                                          o"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0RUqwWJ50JO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "c0b59513-0a2b-400d-d60c-e353534d5897"
      },
      "source": [
        "\n",
        "data1 = data1[data1['speaker'] != 'o']\n",
        "print(data1.count())\n",
        "print(data1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text       51312\n",
            "speaker    51312\n",
            "dtype: int64\n",
            "                                                    text speaker\n",
            "0      There's nothing to tell! He's just some guy I ...       m\n",
            "1      C'mon, you're going out with the guy! There's ...       j\n",
            "2      All right Joey, be nice. So does he have a hum...       c\n",
            "3                               Wait, does he eat chalk?       p\n",
            "5      Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                  ...     ...\n",
            "67368                            Oh, it's gonna be okay.       c\n",
            "67369  Do you guys have to go to the new house right ...       r\n",
            "67370                                  We got some time.       m\n",
            "67371                   Okay, should we get some coffee?       r\n",
            "67372                                       Sure. Where?       c\n",
            "\n",
            "[51312 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVzDbh9FW2wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8808a6b5-12a7-441a-d8c4-cdf223725ef4"
      },
      "source": [
        "data1 = data1.reset_index(drop=True)\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text speaker\n",
            "0      There's nothing to tell! He's just some guy I ...       m\n",
            "1      C'mon, you're going out with the guy! There's ...       j\n",
            "2      All right Joey, be nice. So does he have a hum...       c\n",
            "3                               Wait, does he eat chalk?       p\n",
            "4      Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                  ...     ...\n",
            "51307                            Oh, it's gonna be okay.       c\n",
            "51308  Do you guys have to go to the new house right ...       r\n",
            "51309                                  We got some time.       m\n",
            "51310                   Okay, should we get some coffee?       r\n",
            "51311                                       Sure. Where?       c\n",
            "\n",
            "[51312 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IBFFQjcC3tU",
        "colab_type": "text"
      },
      "source": [
        "#LSTM - nivel de caracter\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr9J6UTjC9lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "06aaeda9-69ef-476e-f031-b6ec9108815e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math\n",
        "\n",
        "import torch.utils.data as utils\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import torchvision\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import collections\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.utils.data as utils\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7ko78sxP4VI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "0139a7d7-b0b2-4abb-d20a-737833c7c7e3"
      },
      "source": [
        "datat = data1[50001:]\n",
        "print(datat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                    text speaker\n",
            "50001          Yeah, you miss alot, when you're moo-ing.       m\n",
            "50002  Oh! It was our pleasure. We are so much enjoyi...       m\n",
            "50003  Oh, uhm, okay, uhm, do you mind if we ask you ...       c\n",
            "50004                                      That's great.       c\n",
            "50005                                    How's that now?       m\n",
            "...                                                  ...     ...\n",
            "51307                            Oh, it's gonna be okay.       c\n",
            "51308  Do you guys have to go to the new house right ...       r\n",
            "51309                                  We got some time.       m\n",
            "51310                   Okay, should we get some coffee?       r\n",
            "51311                                       Sure. Where?       c\n",
            "\n",
            "[1311 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK9FK6aoRAKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "7c1f8191-5529-4f2d-f8ca-6fffbcffe31e"
      },
      "source": [
        "data1 = data1[:5000]\n",
        "print(data1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   text speaker\n",
            "0     There's nothing to tell! He's just some guy I ...       m\n",
            "1     C'mon, you're going out with the guy! There's ...       j\n",
            "2     All right Joey, be nice. So does he have a hum...       c\n",
            "3                              Wait, does he eat chalk?       p\n",
            "4     Just, 'cause, I don't want her to go through w...       p\n",
            "...                                                 ...     ...\n",
            "4995                  You gotta tell Ross how you feel.       j\n",
            "4996  Come on. How can I just tell him? What about J...       r\n",
            "4997  What about her? They've only been going out fo...       j\n",
            "4998                        I don't know, I don't know.       r\n",
            "4999  Look, Rach, Rach! I've been with my share of w...       j\n",
            "\n",
            "[5000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy51TVHoEZOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b7828706-0b8e-42f5-8751-7652ed80eceb"
      },
      "source": [
        "chunk_len = 150\n",
        "\n",
        "# Gera um pedaço aleatório de texto com o tamanho especificado em chuck_len\n",
        "def random_chunk():\n",
        "    index = random.randint(0, len(data1)-1)\n",
        "    \n",
        "    data = data1.iloc[index][0]\n",
        "    \n",
        "    for i in range(200-len(data)):#normaliza os chunks com tamanho igual\n",
        "        data+='/0'\n",
        "        \n",
        "    return data, index\n",
        "    \n",
        "print(random_chunk())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(\"Well, I'm off to Carol's./0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0/0\", 1660)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "que-V2Q8CMpN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWFa64edMRcl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "74bb9d5a-f76e-4c31-a79d-0f883839e37e"
      },
      "source": [
        "file = open('test.txt').read()\n",
        "all_characters = ''.join(set(file))\n",
        "n_characters = len(all_characters)\n",
        "print(all_characters)\n",
        "print(n_characters)\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a;R'-8cWJCiA_H\"7 v6}\n",
            "ny&4G#gNMhBSo5?{Z1$TD!fEUKk9Ye:+jbXmlwOqQxV`LruF[p%3(/>Pz20I]td.s)*,\n",
            "89\n",
            "file_len = 4169043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AlaIuNLIEH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3efc8d1d-d966-46a0-ab0f-59a0545962fd"
      },
      "source": [
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "        try:\n",
        "            tensor[c] = all_characters.index(string[c])\n",
        "        except:\n",
        "            print(c)\n",
        "            raise\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 0, 54,  6, 41, 44, 68])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujFfvD_NIIWK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f953da83-3cdc-47c5-80f2-968d9ddf1824"
      },
      "source": [
        "# Gera um 'exemplo' aleatório (um pedaço aleatório convertido para lista de inteiros)\n",
        "def random_training_set():    \n",
        "    chunk, index = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = data1.iloc[index][-1]\n",
        "    target = char_tensor(target)\n",
        "    return inp, target\n",
        "\n",
        "print(random_training_set())\n",
        "#tensor = random_training_set()\n",
        "#print(tensor)\n",
        "#if(tensor[0][199] == 3) :\n",
        "   # print(\"sim!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 7, 30,  0, 82, 35, 16,  7, 30,  0, 82, 35, 16,  7, 30,  0, 82, 35, 42,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79, 74, 79,\n",
            "        74, 79, 74]), tensor([2]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpngngmGILoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden, hidden2):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, (hidden, hidden2) = self.lstm(input.view(1, 1, -1), (hidden, hidden2))\n",
        "        decoded_output = self.decoder(output.view(1, -1))\n",
        "        return decoded_output, hidden, hidden2\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqP1XbPSKGQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um texto iniciando com \"prime_str\" de tamanho \"predict_len\" e variação definida por \"temperature\"\n",
        "def evaluate(prime_str='A', predict_len=1, temperature=0.8):\n",
        "    hidden = rnn.init_hidden().cuda()\n",
        "    hidden2 = rnn.init_hidden().cuda()\n",
        "    prime_input = char_tensor(prime_str).cuda()\n",
        "    predicted = ''\n",
        "\n",
        "    # prime_str é o texto inicial que o gerado irá completar\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden, hidden2 = rnn(prime_input[p], hidden, hidden2)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden, hidden2 = rnn(inp, hidden, hidden2)\n",
        "        \n",
        "        # Usa a temperatura para amostrar a distribuição e escolher a saída probabilísticamente\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Adiciona o caracter predito à string de saída\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char).cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B727cBfyKO-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treina sobre um exemplo (i.e. uma amostragem do texto)\n",
        "\n",
        "def train(inp, target):\n",
        "    hidden = rnn.init_hidden()\n",
        "    hidden2 = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    inp = inp.cuda()\n",
        "    hidden = hidden.cuda()\n",
        "    hidden2 = hidden2.cuda()\n",
        "    for c in range(chunk_len):\n",
        "        if(inp[c] != 79 or inp[c] != 74):\n",
        "            output, hidden, hidden2 = rnn(inp[c], hidden, hidden2)\n",
        "            loss += loss_metric(output, target[0].unsqueeze(0))\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.data.item() / chunk_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyBV87r7RsGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cHeXrNVKSAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8acde78f-2ad9-4926-b4dc-fff479d845ef"
      },
      "source": [
        "n_epochs = 10000\n",
        "print_every = 100\n",
        "hidden_size = 512\n",
        "n_layers = 4\n",
        "lr = 0.0001\n",
        "\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "rnn.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "loss_metric = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    example = random_training_set()\n",
        "    #print(example[0])\n",
        "    loss = train(example[0].cuda(),example[1].cuda())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "       # print(evaluate('The', 100), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0m 53s (100 1%) 1.5868]\n",
            "[1m 47s (200 2%) 2.3636]\n",
            "[2m 41s (300 3%) 1.8955]\n",
            "[3m 34s (400 4%) 1.8995]\n",
            "[4m 28s (500 5%) 1.5700]\n",
            "[5m 21s (600 6%) 1.8301]\n",
            "[6m 15s (700 7%) 1.8844]\n",
            "[7m 9s (800 8%) 1.7960]\n",
            "[8m 2s (900 9%) 1.7110]\n",
            "[8m 55s (1000 10%) 2.0456]\n",
            "[9m 48s (1100 11%) 1.6487]\n",
            "[10m 42s (1200 12%) 1.8732]\n",
            "[11m 35s (1300 13%) 2.0228]\n",
            "[12m 28s (1400 14%) 2.1389]\n",
            "[13m 22s (1500 15%) 1.8270]\n",
            "[14m 15s (1600 16%) 1.6750]\n",
            "[15m 8s (1700 17%) 1.6697]\n",
            "[16m 1s (1800 18%) 2.0133]\n",
            "[16m 53s (1900 19%) 1.7400]\n",
            "[17m 46s (2000 20%) 1.7579]\n",
            "[18m 40s (2100 21%) 2.1276]\n",
            "[19m 33s (2200 22%) 1.9422]\n",
            "[20m 27s (2300 23%) 1.3426]\n",
            "[21m 20s (2400 24%) 1.8569]\n",
            "[22m 14s (2500 25%) 1.5104]\n",
            "[23m 7s (2600 26%) 1.7614]\n",
            "[24m 1s (2700 27%) 2.0682]\n",
            "[24m 54s (2800 28%) 1.8523]\n",
            "[25m 48s (2900 28%) 2.0649]\n",
            "[26m 41s (3000 30%) 1.5862]\n",
            "[27m 35s (3100 31%) 1.7370]\n",
            "[28m 28s (3200 32%) 1.6329]\n",
            "[29m 22s (3300 33%) 1.3977]\n",
            "[30m 15s (3400 34%) 2.5024]\n",
            "[31m 8s (3500 35%) 1.9550]\n",
            "[32m 1s (3600 36%) 1.6956]\n",
            "[32m 54s (3700 37%) 1.9600]\n",
            "[33m 47s (3800 38%) 1.6346]\n",
            "[34m 41s (3900 39%) 2.2375]\n",
            "[35m 34s (4000 40%) 1.7940]\n",
            "[36m 27s (4100 41%) 1.5568]\n",
            "[37m 21s (4200 42%) 1.6978]\n",
            "[38m 14s (4300 43%) 2.0806]\n",
            "[39m 7s (4400 44%) 1.8598]\n",
            "[40m 1s (4500 45%) 1.5928]\n",
            "[40m 54s (4600 46%) 1.9531]\n",
            "[41m 47s (4700 47%) 1.5875]\n",
            "[42m 41s (4800 48%) 2.1597]\n",
            "[43m 34s (4900 49%) 1.8603]\n",
            "[44m 28s (5000 50%) 1.7780]\n",
            "[45m 21s (5100 51%) 1.6378]\n",
            "[46m 15s (5200 52%) 1.7117]\n",
            "[47m 8s (5300 53%) 1.6471]\n",
            "[48m 2s (5400 54%) 1.9824]\n",
            "[48m 55s (5500 55%) 1.8728]\n",
            "[49m 49s (5600 56%) 1.5543]\n",
            "[50m 42s (5700 56%) 1.9823]\n",
            "[51m 36s (5800 57%) 2.2794]\n",
            "[52m 29s (5900 59%) 1.4301]\n",
            "[53m 23s (6000 60%) 2.1513]\n",
            "[54m 16s (6100 61%) 1.8690]\n",
            "[55m 9s (6200 62%) 1.6089]\n",
            "[56m 3s (6300 63%) 1.7843]\n",
            "[56m 57s (6400 64%) 1.9652]\n",
            "[57m 50s (6500 65%) 1.5813]\n",
            "[58m 44s (6600 66%) 1.9851]\n",
            "[59m 37s (6700 67%) 1.8082]\n",
            "[60m 30s (6800 68%) 1.3460]\n",
            "[61m 23s (6900 69%) 1.7097]\n",
            "[62m 16s (7000 70%) 1.7868]\n",
            "[63m 10s (7100 71%) 1.4935]\n",
            "[64m 3s (7200 72%) 1.5191]\n",
            "[64m 57s (7300 73%) 1.9865]\n",
            "[65m 50s (7400 74%) 1.8131]\n",
            "[66m 42s (7500 75%) 1.6185]\n",
            "[67m 36s (7600 76%) 2.0410]\n",
            "[68m 29s (7700 77%) 1.9169]\n",
            "[69m 23s (7800 78%) 1.7991]\n",
            "[70m 16s (7900 79%) 2.1164]\n",
            "[71m 9s (8000 80%) 1.9598]\n",
            "[72m 2s (8100 81%) 2.2921]\n",
            "[72m 55s (8200 82%) 1.6083]\n",
            "[73m 48s (8300 83%) 2.1645]\n",
            "[74m 42s (8400 84%) 1.7999]\n",
            "[75m 35s (8500 85%) 1.9757]\n",
            "[76m 28s (8600 86%) 1.8585]\n",
            "[77m 22s (8700 87%) 2.0127]\n",
            "[78m 15s (8800 88%) 1.9202]\n",
            "[79m 8s (8900 89%) 1.9362]\n",
            "[80m 2s (9000 90%) 1.9052]\n",
            "[80m 55s (9100 91%) 1.9846]\n",
            "[81m 48s (9200 92%) 1.8462]\n",
            "[82m 42s (9300 93%) 1.3568]\n",
            "[83m 36s (9400 94%) 2.0608]\n",
            "[84m 29s (9500 95%) 1.5613]\n",
            "[85m 23s (9600 96%) 2.4273]\n",
            "[86m 16s (9700 97%) 1.3681]\n",
            "[87m 10s (9800 98%) 1.9750]\n",
            "[88m 3s (9900 99%) 1.9375]\n",
            "[88m 57s (10000 100%) 1.1745]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikiQqwunKy00",
        "colab_type": "text"
      },
      "source": [
        "##Teste LSTM caracter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTBais5aK6iO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# carregar o dataset de test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDpZwbwzLFAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a90fa3c9-5a2c-4ee7-d224-167043b6fc20"
      },
      "source": [
        "#usando o evaluate para avaliar o modelo com o dataset de test\n",
        "datat = datat[datat['text'].map(len) > 15]\n",
        "\n",
        "correct = 0\n",
        "loss = 0\n",
        "\n",
        "for i in range(len(datat)):\n",
        "    predict = evaluate(datat.iloc[i][0])\n",
        "    label = datat.iloc[i][-1]\n",
        "    if(predict == label):\n",
        "        correct+=1\n",
        "    \n",
        "        \n",
        "        \n",
        "        \n",
        "accuracy = correct/(len(datat))\n",
        "\n",
        "\n",
        "\n",
        "print('Acurácia: %d%%'  % (accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4nM_8Ct9lW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}